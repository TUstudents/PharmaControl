{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Closed-Loop Simulation and Performance Analysis\n",
    "\n",
    "**Project:** `PharmaControl-Pro`\n",
    "**Goal:** To close the loop. We will connect our `MPCController` (the brain) to the `AdvancedPlantSimulator` (the body) and run a full steering experiment. This will demonstrate the system's ability to autonomously drive the process to a new target setpoint and allow us to quantitatively analyze its performance.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Setting Up the Closed-Loop Environment](#1.-Setting-Up-the-Closed-Loop-Environment)\n",
    "2. [The Steering Experiment](#2.-The-Steering-Experiment)\n",
    "3. [Visualizing the Steering Performance](#3.-Visualizing-the-Steering-Performance)\n",
    "4. [Quantitative Performance Analysis](#4.-Quantitative-Performance-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Setting Up the Closed-Loop Environment\n",
    "\n",
    "First, we need to load all the components we have built and configured in the previous notebooks:\n",
    "1.  The trained `GranulationPredictor` model.\n",
    "2.  The `MPCController` class, configured with the model, process constraints, and scalers.\n",
    "3.  The `AdvancedPlantSimulator` to act as our real-world process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GranulationPredictor:\n\tMissing key(s) in state_dict: \"transformer.decoder.layers.1.self_attn.in_proj_weight\", \"transformer.decoder.layers.1.self_attn.in_proj_bias\", \"transformer.decoder.layers.1.self_attn.out_proj.weight\", \"transformer.decoder.layers.1.self_attn.out_proj.bias\", \"transformer.decoder.layers.1.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.1.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.1.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.1.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.1.linear1.weight\", \"transformer.decoder.layers.1.linear1.bias\", \"transformer.decoder.layers.1.linear2.weight\", \"transformer.decoder.layers.1.linear2.bias\", \"transformer.decoder.layers.1.norm1.weight\", \"transformer.decoder.layers.1.norm1.bias\", \"transformer.decoder.layers.1.norm2.weight\", \"transformer.decoder.layers.1.norm2.bias\", \"transformer.decoder.layers.1.norm3.weight\", \"transformer.decoder.layers.1.norm3.bias\". \n\tUnexpected key(s) in state_dict: \"transformer.encoder.layers.2.self_attn.in_proj_weight\", \"transformer.encoder.layers.2.self_attn.in_proj_bias\", \"transformer.encoder.layers.2.self_attn.out_proj.weight\", \"transformer.encoder.layers.2.self_attn.out_proj.bias\", \"transformer.encoder.layers.2.linear1.weight\", \"transformer.encoder.layers.2.linear1.bias\", \"transformer.encoder.layers.2.linear2.weight\", \"transformer.encoder.layers.2.linear2.bias\", \"transformer.encoder.layers.2.norm1.weight\", \"transformer.encoder.layers.2.norm1.bias\", \"transformer.encoder.layers.2.norm2.weight\", \"transformer.encoder.layers.2.norm2.bias\". \n\tsize mismatch for cma_encoder_embedding.weight: copying a param with shape torch.Size([128, 2]) from checkpoint, the shape in current model is torch.Size([64, 2]).\n\tsize mismatch for cma_encoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cpp_encoder_embedding.weight: copying a param with shape torch.Size([128, 5]) from checkpoint, the shape in current model is torch.Size([64, 5]).\n\tsize mismatch for cpp_encoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cpp_decoder_embedding.weight: copying a param with shape torch.Size([128, 5]) from checkpoint, the shape in current model is torch.Size([64, 5]).\n\tsize mismatch for cpp_decoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for pos_encoder.pe: copying a param with shape torch.Size([5000, 1, 128]) from checkpoint, the shape in current model is torch.Size([5000, 1, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_linear.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     28\u001b[39m BEST_HPARAMS = {\u001b[33m'\u001b[39m\u001b[33md_model\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m64\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnhead\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_encoder_layers\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_decoder_layers\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.15\u001b[39m}\n\u001b[32m     29\u001b[39m model = GranulationPredictor(\n\u001b[32m     30\u001b[39m     cma_features=\u001b[38;5;28mlen\u001b[39m(CMA_COLS),\n\u001b[32m     31\u001b[39m     cpp_features=\u001b[38;5;28mlen\u001b[39m(CPP_COLS_FULL),\n\u001b[32m     32\u001b[39m     **BEST_HPARAMS\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Load scalers\u001b[39;00m\n\u001b[32m     37\u001b[39m scalers = joblib.load(SCALER_FILE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2624\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2616\u001b[39m         error_msgs.insert(\n\u001b[32m   2617\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2619\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2620\u001b[39m             ),\n\u001b[32m   2621\u001b[39m         )\n\u001b[32m   2623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2624\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2625\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2626\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2627\u001b[39m         )\n\u001b[32m   2628\u001b[39m     )\n\u001b[32m   2629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for GranulationPredictor:\n\tMissing key(s) in state_dict: \"transformer.decoder.layers.1.self_attn.in_proj_weight\", \"transformer.decoder.layers.1.self_attn.in_proj_bias\", \"transformer.decoder.layers.1.self_attn.out_proj.weight\", \"transformer.decoder.layers.1.self_attn.out_proj.bias\", \"transformer.decoder.layers.1.multihead_attn.in_proj_weight\", \"transformer.decoder.layers.1.multihead_attn.in_proj_bias\", \"transformer.decoder.layers.1.multihead_attn.out_proj.weight\", \"transformer.decoder.layers.1.multihead_attn.out_proj.bias\", \"transformer.decoder.layers.1.linear1.weight\", \"transformer.decoder.layers.1.linear1.bias\", \"transformer.decoder.layers.1.linear2.weight\", \"transformer.decoder.layers.1.linear2.bias\", \"transformer.decoder.layers.1.norm1.weight\", \"transformer.decoder.layers.1.norm1.bias\", \"transformer.decoder.layers.1.norm2.weight\", \"transformer.decoder.layers.1.norm2.bias\", \"transformer.decoder.layers.1.norm3.weight\", \"transformer.decoder.layers.1.norm3.bias\". \n\tUnexpected key(s) in state_dict: \"transformer.encoder.layers.2.self_attn.in_proj_weight\", \"transformer.encoder.layers.2.self_attn.in_proj_bias\", \"transformer.encoder.layers.2.self_attn.out_proj.weight\", \"transformer.encoder.layers.2.self_attn.out_proj.bias\", \"transformer.encoder.layers.2.linear1.weight\", \"transformer.encoder.layers.2.linear1.bias\", \"transformer.encoder.layers.2.linear2.weight\", \"transformer.encoder.layers.2.linear2.bias\", \"transformer.encoder.layers.2.norm1.weight\", \"transformer.encoder.layers.2.norm1.bias\", \"transformer.encoder.layers.2.norm2.weight\", \"transformer.encoder.layers.2.norm2.bias\". \n\tsize mismatch for cma_encoder_embedding.weight: copying a param with shape torch.Size([128, 2]) from checkpoint, the shape in current model is torch.Size([64, 2]).\n\tsize mismatch for cma_encoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cpp_encoder_embedding.weight: copying a param with shape torch.Size([128, 5]) from checkpoint, the shape in current model is torch.Size([64, 5]).\n\tsize mismatch for cpp_encoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cpp_decoder_embedding.weight: copying a param with shape torch.Size([128, 5]) from checkpoint, the shape in current model is torch.Size([64, 5]).\n\tsize mismatch for cpp_decoder_embedding.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for pos_encoder.pe: copying a param with shape torch.Size([5000, 1, 128]) from checkpoint, the shape in current model is torch.Size([5000, 1, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([384, 128]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for transformer.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([64, 256]).\n\tsize mismatch for transformer.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer.decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_linear.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import os, sys\n",
    "sys.path.append('..')  # Add parent directory to Python path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import our custom classes\n",
    "from src.plant_simulator import AdvancedPlantSimulator\n",
    "from src.model_architecture import GranulationPredictor\n",
    "from src.mpc_controller import MPCController\n",
    "\n",
    "# --- Configuration and Component Loading ---\n",
    "DATA_DIR = '../data'\n",
    "MODEL_SAVE_PATH = os.path.join(DATA_DIR, 'best_predictor_model.pth')\n",
    "SCALER_FILE = os.path.join(DATA_DIR, 'scalers.joblib')\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define column groups (must match what the model was trained on)\n",
    "CMA_COLS = ['d50', 'lod']\n",
    "CPP_COLS_BASE = ['spray_rate', 'air_flow', 'carousel_speed']\n",
    "CPP_COLS_FULL = ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy']\n",
    "\n",
    "# Load model with saved hyperparameters\n",
    "# In a real app, these would come from a config file\n",
    "BEST_HPARAMS = {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 2, 'num_decoder_layers': 2, 'dropout': 0.15}\n",
    "model = GranulationPredictor(\n",
    "    cma_features=len(CMA_COLS),\n",
    "    cpp_features=len(CPP_COLS_FULL),\n",
    "    **BEST_HPARAMS\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "\n",
    "# Load scalers\n",
    "scalers = joblib.load(SCALER_FILE)\n",
    "\n",
    "# Define process constraints\n",
    "PROCESS_CONSTRAINTS = {\n",
    "    'spray_rate': {'min_val': 80.0, 'max_val': 180.0, 'max_change_per_step': 10.0},\n",
    "    'air_flow': {'min_val': 400.0, 'max_val': 700.0, 'max_change_per_step': 25.0},\n",
    "    'carousel_speed': {'min_val': 20.0, 'max_val': 40.0, 'max_change_per_step': 2.0}\n",
    "}\n",
    "\n",
    "# MPC Configuration\n",
    "MPC_CONFIG = {\n",
    "    'lookback': 36,\n",
    "    'horizon': 72,\n",
    "    'cpp_names': CPP_COLS_BASE,\n",
    "    'cma_names': CMA_COLS,\n",
    "    'cpp_names_and_soft_sensors': CPP_COLS_FULL,\n",
    "    'discretization_steps': 3,\n",
    "    'control_effort_lambda': 0.05\n",
    "}\n",
    "\n",
    "# --- Instantiate the main components ---\n",
    "plant = AdvancedPlantSimulator()\n",
    "mpc_controller = MPCController(model, MPC_CONFIG, PROCESS_CONSTRAINTS, scalers)\n",
    "\n",
    "print(\"Environment ready. All components loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. The Steering Experiment\n",
    "\n",
    "We will now run the main simulation. The experiment will proceed as follows:\n",
    "\n",
    "1.  **Initialization (Steps 0-100):** Run the plant at a fixed initial steady state. This gives the system time to stabilize and provides the controller with enough history (`L` steps) to start making decisions.\n",
    "2.  **Setpoint Change (Time `t=100`):** We issue a new command. We change the target setpoints for `d50` and `LOD`.\n",
    "3.  **Autonomous Control (Steps 101-500):** The MPC controller takes over. At each decision point (e.g., every 5 time steps), it will calculate and apply the optimal control action to drive the plant towards the new target.\n",
    "4.  **Logging:** We will meticulously log the state of the plant (CMAs) and the actions taken by the controller (CPPs) at every time step for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulation Setup ---\n",
    "TOTAL_STEPS = 500\n",
    "STABILIZATION_STEPS = 100\n",
    "MPC_DECISION_INTERVAL = 5 # Make a new decision every 5 steps\n",
    "\n",
    "# Define initial and target states (unscaled)\n",
    "initial_cpps = {'spray_rate': 100.0, 'air_flow': 450.0, 'carousel_speed': 25.0}\n",
    "target_cmas = {'d50': 380.0, 'lod': 1.8}\n",
    "\n",
    "# --- Data Logging ---\n",
    "history_log = []\n",
    "\n",
    "# --- Main Simulation Loop ---\n",
    "current_cpps = initial_cpps\n",
    "pbar = tqdm(range(TOTAL_STEPS), desc=\"Running Closed-Loop Simulation\")\n",
    "\n",
    "for t in pbar:\n",
    "    # Get current plant state\n",
    "    plant_state = plant.step(current_cpps)\n",
    "    \n",
    "    # Log current data\n",
    "    log_entry = {**current_cpps, **plant_state, 'time': t}\n",
    "    history_log.append(log_entry)\n",
    "    \n",
    "    # --- MPC Control Logic ---\n",
    "    # Only start controlling after stabilization and at specified intervals\n",
    "    if t >= STABILIZATION_STEPS and t % MPC_DECISION_INTERVAL == 0:\n",
    "        # 1. Get historical data\n",
    "        df_history = pd.DataFrame(history_log)\n",
    "        recent_history = df_history.tail(MPC_CONFIG['lookback'])\n",
    "        \n",
    "        # 2. Prepare data for the controller (add soft sensors, scale)\n",
    "        # Note: This is a simplified version of the soft-sensor calculation from Notebook 2\n",
    "        recent_history['specific_energy'] = (recent_history['spray_rate'] * recent_history['carousel_speed']) / 1000.0\n",
    "        recent_history['froude_number_proxy'] = (recent_history['carousel_speed']**2) / 9.81\n",
    "\n",
    "        past_cmas_scaled = scalers['d50'].transform(recent_history[['d50']]) # Example\n",
    "        # ... A more robust implementation would loop through all scalers ...\n",
    "        past_cmas_df = recent_history[CMA_COLS].copy()\n",
    "        past_cpps_df = recent_history[CPP_COLS_FULL].copy()\n",
    "        for col in CMA_COLS:\n",
    "            past_cmas_df[col] = scalers[col].transform(past_cmas_df[[col]])\n",
    "        for col in CPP_COLS_FULL:\n",
    "            past_cpps_df[col] = scalers[col].transform(past_cpps_df[[col]])\n",
    "        \n",
    "        # 3. Define the target (tiled over the horizon)\n",
    "        target_unscaled = np.tile([target_cmas['d50'], target_cmas['lod']], (MPC_CONFIG['horizon'], 1))\n",
    "        \n",
    "        # 4. Get the suggested action from the MPC\n",
    "        suggested_action_unscaled = mpc_controller.suggest_action(\n",
    "            past_cmas_df.to_numpy(), \n",
    "            past_cpps_df.to_numpy(), \n",
    "            target_unscaled\n",
    "        )\n",
    "        \n",
    "        # 5. Apply the new action\n",
    "        current_cpps = dict(zip(CPP_COLS_BASE, suggested_action_unscaled))\n",
    "        pbar.set_postfix({'d50': f\"{plant_state['d50']:.1f}\", 'LOD': f\"{plant_state['lod']:.2f}\"})\n",
    "\n",
    "# --- Final DataFrame ---\n",
    "df_results = pd.DataFrame(history_log)\n",
    "print(\"Simulation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Visualizing the Steering Performance\n",
    "\n",
    "Now we plot the results. We want to see if the controller successfully steered the process from the initial state to the new target state. We will create two plots, similar to the paper:\n",
    "1.  A plot of the CMAs over time, showing the target setpoints.\n",
    "2.  A plot of the CPPs over time, showing the controller's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(18, 12), sharex=True)\n",
    "fig.suptitle('Closed-Loop MPC Steering Performance', fontsize=18)\n",
    "\n",
    "# --- Plot 1: CMAs (Process Outputs) ---\n",
    "ax1 = axes[0]\n",
    "ax1.set_title('Process Outputs (CMAs)', fontsize=14)\n",
    "# Plot d50\n",
    "ax1.plot(df_results['time'], df_results['d50'], label='d50 (Actual)', color='dodgerblue', linewidth=2)\n",
    "ax1.axhline(y=target_cmas['d50'], color='blue', linestyle='--', label=f\"d50 Target ({target_cmas['d50']} μm)\")\n",
    "ax1.set_ylabel('d50 (μm)', color='dodgerblue', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor='dodgerblue')\n",
    "\n",
    "# Create a second y-axis for LOD\n",
    "ax1b = ax1.twinx()\n",
    "ax1b.plot(df_results['time'], df_results['lod'], label='LOD (Actual)', color='seagreen', linewidth=2)\n",
    "ax1b.axhline(y=target_cmas['lod'], color='green', linestyle='--', label=f\"LOD Target ({target_cmas['lod']} %)\")\n",
    "ax1b.set_ylabel('LOD (%)', color='seagreen', fontsize=12)\n",
    "ax1b.tick_params(axis='y', labelcolor='seagreen')\n",
    "\n",
    "# Combine legends\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1b.get_legend_handles_labels()\n",
    "ax1b.legend(lines + lines2, labels + labels2, loc='center right')\n",
    "ax1.axvline(x=STABILIZATION_STEPS, color='red', linestyle=':', linewidth=2, label='Control Start')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True)\n",
    "\n",
    "# --- Plot 2: CPPs (Control Inputs) ---\n",
    "ax2 = axes[1]\n",
    "ax2.set_title('Control Inputs (CPPs) Decided by MPC', fontsize=14)\n",
    "for cpp in CPP_COLS_BASE:\n",
    "    ax2.plot(df_results['time'], df_results[cpp], label=cpp, linewidth=2)\n",
    "ax2.set_xlabel('Time Steps', fontsize=12)\n",
    "ax2.set_ylabel('CPP Values')\n",
    "ax2.axvline(x=STABILIZATION_STEPS, color='red', linestyle=':', linewidth=2)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Quantitative Performance Analysis\n",
    "\n",
    "Visual inspection shows the controller is working, but a rigorous analysis requires quantitative metrics. We will measure key characteristics of the control response.\n",
    "\n",
    "*   **Settling Time:** How long did it take for the process to enter and stay within a certain band (e.g., ±5%) of the new target after the control started?\n",
    "*   **Overshoot:** What was the maximum value the process variable reached, as a percentage above the final setpoint?\n",
    "*   **Steady-State Error:** What was the final, average error between the process variable and the target after the system stabilized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(df_results, cma_name, target_value, control_start_time, threshold_percent=0.05):\n",
    "    \"\"\"Calculates key control performance metrics for a given CMA.\"\"\"\n",
    "    # Isolate the controlled portion of the data\n",
    "    controlled_df = df_results[df_results['time'] >= control_start_time]\n",
    "    series = controlled_df[cma_name]\n",
    "    \n",
    "    # --- Overshoot ---\n",
    "    max_val = series.max()\n",
    "    overshoot = ((max_val - target_value) / target_value) * 100 if max_val > target_value else 0\n",
    "    \n",
    "    # --- Settling Time ---\n",
    "    threshold = threshold_percent * target_value\n",
    "    within_band = (series >= target_value - threshold) & (series <= target_value + threshold)\n",
    "    \n",
    "    settling_time = -1\n",
    "    # Find the first time point where all subsequent points are within the band\n",
    "    for i in range(len(within_band)):\n",
    "        if within_band.iloc[i:].all():\n",
    "            settling_time = controlled_df['time'].iloc[i] - control_start_time\n",
    "            break\n",
    "    \n",
    "    # --- Steady-State Error ---\n",
    "    if settling_time != -1:\n",
    "        settled_series = series.iloc[settling_time:]\n",
    "        steady_state_error = (settled_series.mean() - target_value)\n",
    "    else:\n",
    "        steady_state_error = (series.iloc[-20:].mean() - target_value) # Approx if not settled\n",
    "        \n",
    "    return {'overshoot_pct': overshoot, 'settling_time': settling_time, 'steady_state_error': steady_state_error}\n",
    "\n",
    "# --- Calculate and Print Metrics ---\n",
    "print(\"--- Control Performance Metrics ---\")\n",
    "d50_metrics = analyze_performance(df_results, 'd50', target_cmas['d50'], STABILIZATION_STEPS)\n",
    "lod_metrics = analyze_performance(df_results, 'lod', target_cmas['lod'], STABILIZATION_STEPS)\n",
    "\n",
    "print(f\"\\nd50 Performance:\")\n",
    "print(f\"  Overshoot: {d50_metrics['overshoot_pct']:.2f}% (if target was approached from below)\")\n",
    "print(f\"  Settling Time: {d50_metrics['settling_time']} steps\")\n",
    "print(f\"  Steady-State Error: {d50_metrics['steady_state_error']:.3f} μm\")\n",
    "\n",
    "print(f\"\\nLOD Performance:\")\n",
    "print(f\"  Overshoot: {lod_metrics['overshoot_pct']:.2f}% (if target was approached from below)\")\n",
    "print(f\"  Settling Time: {lod_metrics['settling_time']} steps\")\n",
    "print(f\"  Steady-State Error: {lod_metrics['steady_state_error']:.3f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusion\n",
    "\n",
    "Across this five-part series, we have successfully designed, built, and tested a complete, intelligent control system from the ground up.\n",
    "\n",
    "1.  We built a **realistic plant simulator** with nonlinearities and disturbances.\n",
    "2.  We generated and **correctly preprocessed time-series data**, creating a hybrid dataset with soft sensors.\n",
    "3.  We designed and trained a **powerful Transformer-based predictive model** and validated its superiority over a simpler baseline.\n",
    "4.  We encapsulated our control logic in a **robust MPC controller** that respects critical process constraints.\n",
    "5.  Finally, we **closed the loop** and demonstrated through simulation that our system can autonomously and effectively steer the process to a new target, achieving a successful outcome with quantifiable performance.\n",
    "\n",
    "This project provides a comprehensive blueprint for applying modern machine learning and control theory to solve complex, real-world industrial manufacturing challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharmacontrol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
