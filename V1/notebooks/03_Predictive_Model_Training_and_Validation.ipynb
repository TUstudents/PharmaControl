{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Predictive Model Training and Validation\n",
    "\n",
    "**Project:** `PharmaControl-Pro`\n",
    "**Goal:** Build, train, and validate the predictive 'ML kernel' that will power our MPC controller. This involves defining a sophisticated Transformer-based architecture, creating a custom loss function, and using a systematic approach for hyperparameter tuning.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Model Architecture: A Transformer for Time-Series](#1.-Model-Architecture:-A-Transformer-for-Time-Series)\n",
    "2. [Implementing a Custom Loss Function](#2.-Implementing-a-Custom-Loss-Function)\n",
    "3. [Hyperparameter Tuning with Optuna](#3.-Hyperparameter-Tuning-with-Optuna)\n",
    "4. [Training the Final Model](#4.-Training-the-Final-Model)\n",
    "5. [Model Validation and Baseline Comparison](#5.-Model-Validation-and-Baseline-Comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Model Architecture: A Transformer for Time-Series\n",
    "\n",
    "The paper mentions a \"Transformer-inspired\" architecture. We will implement a robust **Encoder-Decoder** model using PyTorch's `nn.Transformer` components. This architecture is well-suited for sequence-to-sequence tasks like ours.\n",
    "\n",
    "*   **Encoder:** Its job is to read the historical data (the last `L` steps of CMAs and CPPs) and compress this information into a rich, contextualized memory. It uses self-attention to understand the relationships within the historical sequence.\n",
    "*   **Decoder:** Its job is to generate the future prediction. At each future time step `t` (from 1 to `H`), it looks at the entire encoded memory (via cross-attention) and combines that context with the *planned* control action for that future step (`future_U[t]`) to make a prediction. This structure explicitly models the relationship between future actions and future outcomes.\n",
    "\n",
    "We will define this model in `src/model_architecture.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/model_architecture.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/model_architecture.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Injects positional information into the input sequence.\"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class GranulationPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-based Encoder-Decoder model for predicting granulation CMAs.\n",
    "    \"\"\"\n",
    "    def __init__(self, cma_features, cpp_features, d_model=64, nhead=4, \n",
    "                 num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # --- Input Embeddings ---\n",
    "        self.cma_encoder_embedding = nn.Linear(cma_features, d_model)\n",
    "        self.cpp_encoder_embedding = nn.Linear(cpp_features, d_model)\n",
    "        self.cpp_decoder_embedding = nn.Linear(cpp_features, d_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # --- Transformer --- \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # --- Output Layer ---\n",
    "        # Maps the decoder output back to the desired number of CMA features\n",
    "        self.output_linear = nn.Linear(d_model, cma_features)\n",
    "        \n",
    "    def forward(self, past_cmas, past_cpps, future_cpps):\n",
    "        # src: source sequence to the encoder (historical data)\n",
    "        # tgt: target sequence to the decoder (planned future actions)\n",
    "        \n",
    "        # Embed and combine historical inputs for the encoder\n",
    "        past_cma_emb = self.cma_encoder_embedding(past_cmas)\n",
    "        past_cpp_emb = self.cpp_encoder_embedding(past_cpps)\n",
    "        src = self.pos_encoder(past_cma_emb + past_cpp_emb)\n",
    "        \n",
    "        # Embed future control actions for the decoder\n",
    "        tgt = self.pos_encoder(self.cpp_decoder_embedding(future_cpps))\n",
    "        \n",
    "        # The decoder needs a target mask to prevent it from seeing future positions\n",
    "        # when making a prediction at the current position.\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        \n",
    "        # Pass through the transformer\n",
    "        output = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        \n",
    "        # Final linear layer to get CMA predictions\n",
    "        prediction = self.output_linear(output)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Implementing a Custom Loss Function\n",
    "\n",
    "The paper mentions a custom loss function designed to \"prevent fitting irrelevant short-time dynamics.\" This implies that errors further out in the prediction horizon are more important than immediate, transient errors.\n",
    "\n",
    "We can implement this by creating a **weighted Mean Squared Error (MSE)** loss. We'll assign a weight to each of the `H` steps in the horizon, with weights increasing over time. This forces the model to prioritize long-term accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedHorizonMSELoss(nn.Module):\n",
    "    \"\"\"Calculates MSE with a linearly increasing weight over the horizon.\"\"\"\n",
    "    def __init__(self, horizon: int, start_weight: float = 0.5, end_weight: float = 1.5):\n",
    "        super().__init__()\n",
    "        # Create a weight tensor of shape (1, horizon, 1) for broadcasting\n",
    "        weights = torch.linspace(start_weight, end_weight, horizon).view(1, -1, 1)\n",
    "        self.register_buffer('weights', weights)\n",
    "        \n",
    "    def forward(self, prediction, target):\n",
    "        # prediction and target shape: (batch_size, horizon, features)\n",
    "        loss = (prediction - target) ** 2\n",
    "        weighted_loss = loss * self.weights\n",
    "        return torch.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hyperparameter Tuning with Optuna\n",
    "\n",
    "Choosing the right hyperparameters (like learning rate, model size, etc.) is critical for performance. Manually guessing these values is inefficient. We will use **Optuna**, a powerful hyperparameter optimization framework, to systematically search for the best combination.\n",
    "\n",
    "We'll define an `objective` function that takes a trial, builds a model with the suggested hyperparameters, trains it for a few epochs, and returns the validation loss. Optuna will then intelligently choose the next set of hyperparameters to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 10:40:36,880] A new study created in memory with name: no-name-18c626c7-4575-40e2-b595-cc83c3f64431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 11:00:00,799] Trial 0 finished with value: 0.10489445968585856 and parameters: {'d_model': 32, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'lr': 2.4571595871276294e-05, 'dropout': 0.19456572268554695}. Best is trial 0 with value: 0.10489445968585856.\n",
      "[I 2025-08-10 11:06:24,372] Trial 1 finished with value: 0.004219044903841089 and parameters: {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 1, 'lr': 0.00044953570163473993, 'dropout': 0.1828474538869418}. Best is trial 1 with value: 0.004219044903841089.\n",
      "[I 2025-08-10 11:17:17,528] Trial 2 finished with value: 0.009560377200079314 and parameters: {'d_model': 128, 'nhead': 2, 'num_encoder_layers': 2, 'num_decoder_layers': 3, 'lr': 0.000808170970206889, 'dropout': 0.2833651799731518}. Best is trial 1 with value: 0.004219044903841089.\n",
      "[I 2025-08-10 11:30:18,198] Trial 3 finished with value: 0.02105267274686519 and parameters: {'d_model': 64, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 3, 'lr': 4.8703583555117624e-05, 'dropout': 0.2053185714054171}. Best is trial 1 with value: 0.004219044903841089.\n",
      "[W 2025-08-10 11:38:51,491] Trial 4 failed with parameters: {'d_model': 128, 'nhead': 2, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'lr': 1.7033208053132842e-05, 'dropout': 0.11098389854654125} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/feynman/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_55749/589942.py\", line 59, in objective\n",
      "    loss.backward()\n",
      "  File \"/home/feynman/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/feynman/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/feynman/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-10 11:38:51,551] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# --- Run the Optuna Study ---\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Note: This can take a long time. For a real run, use n_trials=50 or more.\u001b[39;00m\n\u001b[32m     75\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Use 20 trials for demonstration\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial found:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m best_trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     57\u001b[39m         prediction = model(past_cmas, past_cpps, future_cpps)\n\u001b[32m     58\u001b[39m         loss = criterion(prediction, future_cmas_target)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m         \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m         optimizer.step()\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- Final Validation ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append('..')  # Add parent directory to Python path\n",
    "from src.model_architecture import GranulationPredictor\n",
    "from src.dataset import GranulationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Load Pre-processed Data (from Notebook 2) ---\n",
    "DATA_DIR = '../data'\n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train_data.csv'))\n",
    "df_val = pd.read_csv(os.path.join(DATA_DIR, 'validation_data.csv'))\n",
    "CMA_COLS = ['d50', 'lod']\n",
    "CPP_COLS = ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy']\n",
    "LOOKBACK = 36\n",
    "HORIZON = 72\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter tuning.\"\"\"\n",
    "    # --- Hyperparameters to Tune ---\n",
    "    d_model = trial.suggest_categorical('d_model', [32, 64, 128])\n",
    "    nhead = trial.suggest_categorical('nhead', [2, 4, 8])\n",
    "    num_encoder_layers = trial.suggest_int('num_encoder_layers', 1, 3)\n",
    "    num_decoder_layers = trial.suggest_int('num_decoder_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.3)\n",
    "    \n",
    "    # --- Model, Loss, Optimizer ---\n",
    "    model = GranulationPredictor(\n",
    "        cma_features=len(CMA_COLS),\n",
    "        cpp_features=len(CPP_COLS),\n",
    "        d_model=d_model, nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        dropout=dropout\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    criterion = WeightedHorizonMSELoss(horizon=HORIZON).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # --- DataLoaders ---\n",
    "    train_dataset = GranulationDataset(df_train, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "    val_dataset = GranulationDataset(df_val, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # --- Training & Validation Loop (abbreviated for tuning) ---\n",
    "    NUM_EPOCHS_TUNE = 5 # Use fewer epochs for faster tuning\n",
    "    for epoch in range(NUM_EPOCHS_TUNE):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(past_cmas, past_cpps, future_cpps)\n",
    "            loss = criterion(prediction, future_cmas_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # --- Final Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            prediction = model(past_cmas, past_cpps, future_cpps)\n",
    "            val_loss += criterion(prediction, future_cmas_target).item()\n",
    "    \n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# --- Run the Optuna Study ---\n",
    "# Note: This can take a long time. For a real run, use n_trials=50 or more.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=4) # Use 20 trials for demonstration\n",
    "\n",
    "print(\"Best trial found:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial\n",
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FrozenTrial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#best_trial=optuna.create_study(direction='minimize').best_trial\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m best_trial=\u001b[43mFrozenTrial\u001b[49m(number=\u001b[32m1\u001b[39m, state=\u001b[32m1\u001b[39m, values=[\u001b[32m0.004219044903841089\u001b[39m], datetime_start=datetime.datetime(\u001b[32m2025\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m11\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m800698\u001b[39m), datetime_complete=datetime.datetime(\u001b[32m2025\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m11\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m24\u001b[39m, \u001b[32m372024\u001b[39m), params={\u001b[33m'\u001b[39m\u001b[33md_model\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnhead\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_encoder_layers\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_decoder_layers\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.00044953570163473993\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.1828474538869418\u001b[39m}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={\u001b[33m'\u001b[39m\u001b[33md_model\u001b[39m\u001b[33m'\u001b[39m: CategoricalDistribution(choices=(\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m)), \u001b[33m'\u001b[39m\u001b[33mnhead\u001b[39m\u001b[33m'\u001b[39m: CategoricalDistribution(choices=(\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m)), \u001b[33m'\u001b[39m\u001b[33mnum_encoder_layers\u001b[39m\u001b[33m'\u001b[39m: IntDistribution(high=\u001b[32m3\u001b[39m, log=\u001b[38;5;28;01mFalse\u001b[39;00m, low=\u001b[32m1\u001b[39m, step=\u001b[32m1\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mnum_decoder_layers\u001b[39m\u001b[33m'\u001b[39m: IntDistribution(high=\u001b[32m3\u001b[39m, log=\u001b[38;5;28;01mFalse\u001b[39;00m, low=\u001b[32m1\u001b[39m, step=\u001b[32m1\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: FloatDistribution(high=\u001b[32m0.001\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m, low=\u001b[32m1e-05\u001b[39m, step=\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m: FloatDistribution(high=\u001b[32m0.3\u001b[39m, log=\u001b[38;5;28;01mFalse\u001b[39;00m, low=\u001b[32m0.1\u001b[39m, step=\u001b[38;5;28;01mNone\u001b[39;00m)}, trial_id=\u001b[32m1\u001b[39m, value=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'FrozenTrial' is not defined"
     ]
    }
   ],
   "source": [
    "#best_trial=optuna.create_study(direction='minimize').best_trial\n",
    "\n",
    "best_trial=FrozenTrial(number=1, state=1, values=[0.004219044903841089], datetime_start=datetime.datetime(2025, 8, 10, 11, 0, 0, 800698), datetime_complete=datetime.datetime(2025, 8, 10, 11, 6, 24, 372024), params={'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 1, 'lr': 0.00044953570163473993, 'dropout': 0.1828474538869418}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'d_model': CategoricalDistribution(choices=(32, 64, 128)), 'nhead': CategoricalDistribution(choices=(2, 4, 8)), 'num_encoder_layers': IntDistribution(high=3, log=False, low=1, step=1), 'num_decoder_layers': IntDistribution(high=3, log=False, low=1, step=1), 'lr': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'dropout': FloatDistribution(high=0.3, log=False, low=0.1, step=None)}, trial_id=1, value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Training the Final Model\n",
    "\n",
    "Now that we have the best hyperparameters from our Optuna study, we will train a new model from scratch using these parameters for a larger number of epochs to ensure it converges properly. We will also implement early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [T]: 100%|██████████| 82/82 [04:26<00:00,  3.25s/it, loss=0.0285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 0.010200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [T]: 100%|██████████| 82/82 [04:18<00:00,  3.15s/it, loss=0.0151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Validation Loss: 0.004567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [T]: 100%|██████████| 82/82 [04:30<00:00,  3.30s/it, loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Validation Loss: 0.005602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [T]: 100%|██████████| 82/82 [01:26<00:00,  1.05s/it, loss=0.00951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Validation Loss: 0.005516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [T]: 100%|██████████| 82/82 [01:55<00:00,  1.41s/it, loss=0.00774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Validation Loss: 0.005098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [T]: 100%|██████████| 82/82 [04:22<00:00,  3.20s/it, loss=0.00679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Validation Loss: 0.005015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [T]: 100%|██████████| 82/82 [04:47<00:00,  3.51s/it, loss=0.00643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Validation Loss: 0.004575\n",
      "Early stopping triggered after 7 epochs.\n",
      "Final model saved to ../data/best_predictor_model.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Final Model Training ---\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "BEST_HPARAMS = best_trial.params\n",
    "MODEL_SAVE_PATH = os.path.join(DATA_DIR, 'best_predictor_model.pth')\n",
    "NUM_EPOCHS_FINAL = 10   # Use 50 epochs for final training\n",
    "PATIENCE = 5 # For early stopping\n",
    "\n",
    "# Re-create datasets and loaders\n",
    "train_dataset = GranulationDataset(df_train, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "val_dataset = GranulationDataset(df_val, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "final_model = GranulationPredictor(\n",
    "    cma_features=len(CMA_COLS),\n",
    "    cpp_features=len(CPP_COLS),\n",
    "    d_model=BEST_HPARAMS['d_model'], nhead=BEST_HPARAMS['nhead'],\n",
    "    num_encoder_layers=BEST_HPARAMS['num_encoder_layers'],\n",
    "    num_decoder_layers=BEST_HPARAMS['num_decoder_layers'],\n",
    "    dropout=BEST_HPARAMS['dropout']\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = WeightedHorizonMSELoss(horizon=HORIZON).to(DEVICE)\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=BEST_HPARAMS['lr'])\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = copy.deepcopy(final_model.state_dict())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_FINAL):\n",
    "    final_model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS_FINAL} [T]\")\n",
    "    for batch in pbar:\n",
    "        past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        prediction = final_model(past_cmas, past_cpps, future_cpps)\n",
    "        loss = criterion(prediction, future_cmas_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    current_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            prediction = final_model(past_cmas, past_cpps, future_cpps)\n",
    "            current_val_loss += criterion(prediction, future_cmas_target).item()\n",
    "    avg_val_loss = current_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.6f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_wts = copy.deepcopy(final_model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load best model weights and save\n",
    "final_model.load_state_dict(best_model_wts)\n",
    "torch.save(final_model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Final model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Validation and Baseline Comparison\n",
    "\n",
    "The final step is to perform an unbiased evaluation of our trained model on the held-out test set. We will visualize its predictions and calculate the Mean Absolute Error (MAE), comparing it to a simpler baseline model to prove the value of our complex architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/test_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_test = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m test_dataset = GranulationDataset(df_test, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n\u001b[32m      6\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m1\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Batch size 1 for individual plots\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/test_data.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, 'test_data.csv'))\n",
    "test_dataset = GranulationDataset(df_test, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False) # Batch size 1 for individual plots\n",
    "\n",
    "# Load scalers for inverse transform\n",
    "scalers = joblib.load(os.path.join(DATA_DIR, 'scalers.joblib'))\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get one sample from the test set\n",
    "    past_cmas, past_cpps, future_cpps, future_cmas_target = next(iter(test_loader))\n",
    "    past_cmas, past_cpps, future_cpps = [b.to(DEVICE) for b in [past_cmas, past_cpps, future_cpps]]\n",
    "    \n",
    "    prediction_scaled = final_model(past_cmas, past_cpps, future_cpps).squeeze(0).cpu().numpy()\n",
    "    target_scaled = future_cmas_target.squeeze(0).cpu().numpy()\n",
    "\n",
    "# Inverse transform to original scale for plotting\n",
    "prediction_unscaled = np.zeros_like(prediction_scaled)\n",
    "target_unscaled = np.zeros_like(target_scaled)\n",
    "for i, col in enumerate(CMA_COLS):\n",
    "    prediction_unscaled[:, i] = scalers[col].inverse_transform(prediction_scaled[:, i].reshape(-1, 1)).flatten()\n",
    "    target_unscaled[:, i] = scalers[col].inverse_transform(target_scaled[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# --- Plotting --- \n",
    "fig, axes = plt.subplots(len(CMA_COLS), 1, figsize=(15, 8), sharex=True)\n",
    "fig.suptitle('Model Prediction vs. Ground Truth on Test Set', fontsize=16)\n",
    "for i, col in enumerate(CMA_COLS):\n",
    "    axes[i].plot(target_unscaled[:, i], label='Ground Truth', color='blue', linestyle='--')\n",
    "    axes[i].plot(prediction_unscaled[:, i], label='Prediction', color='red')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "axes[-1].set_xlabel('Time Steps into Horizon')\n",
    "plt.show()\n",
    "\n",
    "# TODO: Implement and train a baseline MLP model and compare its final test MAE here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharmacontrol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
