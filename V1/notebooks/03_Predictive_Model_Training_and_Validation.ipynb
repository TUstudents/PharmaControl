{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Predictive Model Training and Validation\n",
    "\n",
    "**Project:** `PharmaControl-Pro`\n",
    "**Goal:** Build, train, and validate the predictive 'ML kernel' that will power our MPC controller. This involves defining a sophisticated Transformer-based architecture, creating a custom loss function, and using a systematic approach for hyperparameter tuning.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Model Architecture: A Transformer for Time-Series](#1.-Model-Architecture:-A-Transformer-for-Time-Series)\n",
    "2. [Implementing a Custom Loss Function](#2.-Implementing-a-Custom-Loss-Function)\n",
    "3. [Hyperparameter Tuning with Optuna](#3.-Hyperparameter-Tuning-with-Optuna)\n",
    "4. [Training the Final Model](#4.-Training-the-Final-Model)\n",
    "5. [Model Validation and Baseline Comparison](#5.-Model-Validation-and-Baseline-Comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Model Architecture: A Transformer for Time-Series\n",
    "\n",
    "The paper mentions a \"Transformer-inspired\" architecture. We will implement a robust **Encoder-Decoder** model using PyTorch's `nn.Transformer` components. This architecture is well-suited for sequence-to-sequence tasks like ours.\n",
    "\n",
    "*   **Encoder:** Its job is to read the historical data (the last `L` steps of CMAs and CPPs) and compress this information into a rich, contextualized memory. It uses self-attention to understand the relationships within the historical sequence.\n",
    "*   **Decoder:** Its job is to generate the future prediction. At each future time step `t` (from 1 to `H`), it looks at the entire encoded memory (via cross-attention) and combines that context with the *planned* control action for that future step (`future_U[t]`) to make a prediction. This structure explicitly models the relationship between future actions and future outcomes.\n",
    "\n",
    "We will define this model in `src/model_architecture.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/model_architecture.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/model_architecture.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Injects positional information into the input sequence.\"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class GranulationPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-based Encoder-Decoder model for predicting granulation CMAs.\n",
    "    \"\"\"\n",
    "    def __init__(self, cma_features, cpp_features, d_model=64, nhead=4, \n",
    "                 num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # --- Input Embeddings ---\n",
    "        self.cma_encoder_embedding = nn.Linear(cma_features, d_model)\n",
    "        self.cpp_encoder_embedding = nn.Linear(cpp_features, d_model)\n",
    "        self.cpp_decoder_embedding = nn.Linear(cpp_features, d_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # --- Transformer --- \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # --- Output Layer ---\n",
    "        # Maps the decoder output back to the desired number of CMA features\n",
    "        self.output_linear = nn.Linear(d_model, cma_features)\n",
    "        \n",
    "    def forward(self, past_cmas, past_cpps, future_cpps):\n",
    "        # src: source sequence to the encoder (historical data)\n",
    "        # tgt: target sequence to the decoder (planned future actions)\n",
    "        \n",
    "        # Embed and combine historical inputs for the encoder\n",
    "        past_cma_emb = self.cma_encoder_embedding(past_cmas)\n",
    "        past_cpp_emb = self.cpp_encoder_embedding(past_cpps)\n",
    "        src = self.pos_encoder(past_cma_emb + past_cpp_emb)\n",
    "        \n",
    "        # Embed future control actions for the decoder\n",
    "        tgt = self.pos_encoder(self.cpp_decoder_embedding(future_cpps))\n",
    "        \n",
    "        # The decoder needs a target mask to prevent it from seeing future positions\n",
    "        # when making a prediction at the current position.\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        \n",
    "        # Pass through the transformer\n",
    "        output = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        \n",
    "        # Final linear layer to get CMA predictions\n",
    "        prediction = self.output_linear(output)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Implementing a Custom Loss Function\n",
    "\n",
    "The paper mentions a custom loss function designed to \"prevent fitting irrelevant short-time dynamics.\" This implies that errors further out in the prediction horizon are more important than immediate, transient errors.\n",
    "\n",
    "We can implement this by creating a **weighted Mean Squared Error (MSE)** loss. We'll assign a weight to each of the `H` steps in the horizon, with weights increasing over time. This forces the model to prioritize long-term accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedHorizonMSELoss(nn.Module):\n",
    "    \"\"\"Calculates MSE with a linearly increasing weight over the horizon.\"\"\"\n",
    "    def __init__(self, horizon: int, start_weight: float = 0.5, end_weight: float = 1.5):\n",
    "        super().__init__()\n",
    "        # Create a weight tensor of shape (1, horizon, 1) for broadcasting\n",
    "        weights = torch.linspace(start_weight, end_weight, horizon).view(1, -1, 1)\n",
    "        self.register_buffer('weights', weights)\n",
    "        \n",
    "    def forward(self, prediction, target):\n",
    "        # prediction and target shape: (batch_size, horizon, features)\n",
    "        loss = (prediction - target) ** 2\n",
    "        weighted_loss = loss * self.weights\n",
    "        return torch.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hyperparameter Tuning with Optuna\n",
    "\n",
    "Choosing the right hyperparameters (like learning rate, model size, etc.) is critical for performance. Manually guessing these values is inefficient. We will use **Optuna**, a powerful hyperparameter optimization framework, to systematically search for the best combination.\n",
    "\n",
    "We'll define an `objective` function that takes a trial, builds a model with the suggested hyperparameters, trains it for a few epochs, and returns the validation loss. Optuna will then intelligently choose the next set of hyperparameters to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 04:22:01,146] A new study created in memory with name: no-name-c684ecfa-4828-4fc5-8fbe-007c0b004710\n",
      "[I 2025-08-11 04:30:10,517] Trial 0 finished with value: 0.11015949748894747 and parameters: {'d_model': 32, 'nhead': 2, 'num_encoder_layers': 1, 'num_decoder_layers': 2, 'lr': 1.2821130237925689e-05, 'dropout': 0.17258260070762318}. Best is trial 0 with value: 0.11015949748894747.\n",
      "[I 2025-08-11 04:53:59,368] Trial 1 finished with value: 0.008515874800436637 and parameters: {'d_model': 64, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 3, 'lr': 0.0001892126403831818, 'dropout': 0.2931766576970832}. Best is trial 1 with value: 0.008515874800436637.\n",
      "[I 2025-08-11 04:55:54,443] Trial 2 finished with value: 0.006501479471540626 and parameters: {'d_model': 32, 'nhead': 2, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 0.0005239860415912874, 'dropout': 0.16107836352578545}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:04:49,936] Trial 3 finished with value: 0.006720552193548749 and parameters: {'d_model': 64, 'nhead': 8, 'num_encoder_layers': 1, 'num_decoder_layers': 3, 'lr': 0.0001758121949142109, 'dropout': 0.26036460800082784}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:15:38,276] Trial 4 finished with value: 0.011636106626075856 and parameters: {'d_model': 128, 'nhead': 2, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'lr': 0.00020139703203333022, 'dropout': 0.2917496359156396}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:19:08,978] Trial 5 finished with value: 0.14218421630999623 and parameters: {'d_model': 32, 'nhead': 2, 'num_encoder_layers': 1, 'num_decoder_layers': 3, 'lr': 2.932667861480585e-05, 'dropout': 0.1315980872520282}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:23:14,265] Trial 6 finished with value: 0.006857867818325758 and parameters: {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 1, 'num_decoder_layers': 1, 'lr': 0.0001212895641782899, 'dropout': 0.19312414822840862}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:28:07,171] Trial 7 finished with value: 0.02984323341618566 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 1, 'num_decoder_layers': 1, 'lr': 1.1661960796499495e-05, 'dropout': 0.22895292627911493}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:34:37,768] Trial 8 finished with value: 0.07410939563723172 and parameters: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 2, 'num_decoder_layers': 3, 'lr': 1.3750558216264988e-05, 'dropout': 0.1253746552975939}. Best is trial 2 with value: 0.006501479471540626.\n",
      "[I 2025-08-11 05:40:19,731] Trial 9 finished with value: 0.00410553630824913 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 0.00032353237853923844, 'dropout': 0.158494889759869}. Best is trial 9 with value: 0.00410553630824913.\n",
      "[I 2025-08-11 05:50:08,209] Trial 10 finished with value: 0.004410315291298663 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 0.0009944505088592286, 'dropout': 0.1015975591742275}. Best is trial 9 with value: 0.00410553630824913.\n",
      "[I 2025-08-11 05:59:57,673] Trial 11 finished with value: 0.0030854975133586455 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 0.000838934349288504, 'dropout': 0.10122835808149047}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:09:53,960] Trial 12 finished with value: 0.005417473668999532 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 0.00045813025847421534, 'dropout': 0.14314434380149482}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:19:40,114] Trial 13 finished with value: 0.004277596695293837 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 0.0009914813448353595, 'dropout': 0.10340606557884024}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:25:36,970] Trial 14 finished with value: 0.005280458532712039 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 0.0003861388393282215, 'dropout': 0.215152379802314}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:31:16,190] Trial 15 finished with value: 0.006552675095222452 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 6.797918752311331e-05, 'dropout': 0.17593301900669162}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:39:35,982] Trial 16 finished with value: 0.004244034835959182 and parameters: {'d_model': 128, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 0.0003248863816567458, 'dropout': 0.14165218763729504}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:45:22,882] Trial 17 finished with value: 0.003926085226018639 and parameters: {'d_model': 128, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 0.0006530555477134919, 'dropout': 0.19585918617102338}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:51:18,970] Trial 18 finished with value: 0.07018373271121699 and parameters: {'d_model': 32, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'lr': 6.082729144129769e-05, 'dropout': 0.2446612085086785}. Best is trial 11 with value: 0.0030854975133586455.\n",
      "[I 2025-08-11 06:54:28,876] Trial 19 finished with value: 0.0037603735690936446 and parameters: {'d_model': 64, 'nhead': 4, 'num_encoder_layers': 2, 'num_decoder_layers': 1, 'lr': 0.0006449596299592912, 'dropout': 0.20119960164127007}. Best is trial 11 with value: 0.0030854975133586455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial found:\n",
      "  Value: 0.0030854975133586455\n",
      "  Params: \n",
      "    d_model: 128\n",
      "    nhead: 8\n",
      "    num_encoder_layers: 3\n",
      "    num_decoder_layers: 2\n",
      "    lr: 0.000838934349288504\n",
      "    dropout: 0.10122835808149047\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append('..')  # Add parent directory to Python path\n",
    "from src.model_architecture import GranulationPredictor\n",
    "from src.dataset import GranulationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Load Pre-processed Data (from Notebook 2) ---\n",
    "DATA_DIR = '../data'\n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train_data.csv'))\n",
    "df_val = pd.read_csv(os.path.join(DATA_DIR, 'validation_data.csv'))\n",
    "CMA_COLS = ['d50', 'lod']\n",
    "CPP_COLS = ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy']\n",
    "LOOKBACK = 36\n",
    "HORIZON = 72\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter tuning.\"\"\"\n",
    "    # --- Hyperparameters to Tune ---\n",
    "    d_model = trial.suggest_categorical('d_model', [32, 64, 128])\n",
    "    nhead = trial.suggest_categorical('nhead', [2, 4, 8])\n",
    "    num_encoder_layers = trial.suggest_int('num_encoder_layers', 1, 3)\n",
    "    num_decoder_layers = trial.suggest_int('num_decoder_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.3)\n",
    "    \n",
    "    # --- Model, Loss, Optimizer ---\n",
    "    model = GranulationPredictor(\n",
    "        cma_features=len(CMA_COLS),\n",
    "        cpp_features=len(CPP_COLS),\n",
    "        d_model=d_model, nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        dropout=dropout\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    criterion = WeightedHorizonMSELoss(horizon=HORIZON).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # --- DataLoaders ---\n",
    "    train_dataset = GranulationDataset(df_train, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "    val_dataset = GranulationDataset(df_val, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # --- Training & Validation Loop (abbreviated for tuning) ---\n",
    "    NUM_EPOCHS_TUNE = 5 # Use fewer epochs for faster tuning\n",
    "    for epoch in range(NUM_EPOCHS_TUNE):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(past_cmas, past_cpps, future_cpps)\n",
    "            loss = criterion(prediction, future_cmas_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # --- Final Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            prediction = model(past_cmas, past_cpps, future_cpps)\n",
    "            val_loss += criterion(prediction, future_cmas_target).item()\n",
    "    \n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# --- Run the Optuna Study ---\n",
    "# Note: This can take a long time. For a real run, use n_trials=50 or more.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20) # Use 20 trials for demonstration\n",
    "\n",
    "print(\"Best trial found:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial\n",
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#best_trial=optuna.create_study(direction='minimize').best_trial\n",
    "Best trial found:\n",
    "  Value: 0.0030854975133586455\n",
    "  Params: \n",
    "    d_model: 128\n",
    "    nhead: 8\n",
    "    num_encoder_layers: 3\n",
    "    num_decoder_layers: 2\n",
    "    lr: 0.000838934349288504\n",
    "    dropout: 0.10122835808149047"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Training the Final Model\n",
    "\n",
    "Now that we have the best hyperparameters from our Optuna study, we will train a new model from scratch using these parameters for a larger number of epochs to ensure it converges properly. We will also implement early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [T]: 100%|██████████| 82/82 [06:23<00:00,  4.67s/it, loss=0.0549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 0.135291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [T]: 100%|██████████| 82/82 [06:27<00:00,  4.73s/it, loss=0.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Validation Loss: 0.004649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [T]: 100%|██████████| 82/82 [06:29<00:00,  4.75s/it, loss=0.00797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Validation Loss: 0.004767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [T]: 100%|██████████| 82/82 [06:39<00:00,  4.87s/it, loss=0.00625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Validation Loss: 0.003481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [T]: 100%|██████████| 82/82 [06:46<00:00,  4.96s/it, loss=0.00608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Validation Loss: 0.003709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [T]: 100%|██████████| 82/82 [06:24<00:00,  4.69s/it, loss=0.00469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Validation Loss: 0.003002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [T]: 100%|██████████| 82/82 [04:04<00:00,  2.98s/it, loss=0.00417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Validation Loss: 0.005967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [T]: 100%|██████████| 82/82 [01:50<00:00,  1.35s/it, loss=0.00521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Validation Loss: 0.003038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [T]: 100%|██████████| 82/82 [01:50<00:00,  1.35s/it, loss=0.00363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Validation Loss: 0.003246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [T]: 100%|██████████| 82/82 [01:55<00:00,  1.41s/it, loss=0.00387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Validation Loss: 0.002896\n",
      "Final model saved to ../data/best_predictor_model.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Final Model Training ---\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "BEST_HPARAMS = best_trial.params\n",
    "MODEL_SAVE_PATH = os.path.join(DATA_DIR, 'best_predictor_model.pth')\n",
    "NUM_EPOCHS_FINAL = 10   # Use 50 epochs for final training\n",
    "PATIENCE = 5 # For early stopping\n",
    "\n",
    "# Re-create datasets and loaders\n",
    "train_dataset = GranulationDataset(df_train, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "val_dataset = GranulationDataset(df_val, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "final_model = GranulationPredictor(\n",
    "    cma_features=len(CMA_COLS),\n",
    "    cpp_features=len(CPP_COLS),\n",
    "    d_model=BEST_HPARAMS['d_model'], nhead=BEST_HPARAMS['nhead'],\n",
    "    num_encoder_layers=BEST_HPARAMS['num_encoder_layers'],\n",
    "    num_decoder_layers=BEST_HPARAMS['num_decoder_layers'],\n",
    "    dropout=BEST_HPARAMS['dropout']\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = WeightedHorizonMSELoss(horizon=HORIZON).to(DEVICE)\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=BEST_HPARAMS['lr'])\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = copy.deepcopy(final_model.state_dict())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_FINAL):\n",
    "    final_model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS_FINAL} [T]\")\n",
    "    for batch in pbar:\n",
    "        past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        prediction = final_model(past_cmas, past_cpps, future_cpps)\n",
    "        loss = criterion(prediction, future_cmas_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    current_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            past_cmas, past_cpps, future_cpps, future_cmas_target = [b.to(DEVICE) for b in batch]\n",
    "            prediction = final_model(past_cmas, past_cpps, future_cpps)\n",
    "            current_val_loss += criterion(prediction, future_cmas_target).item()\n",
    "    avg_val_loss = current_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.6f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_wts = copy.deepcopy(final_model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load best model weights and save\n",
    "final_model.load_state_dict(best_model_wts)\n",
    "torch.save(final_model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Final model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Validation and Baseline Comparison\n",
    "\n",
    "The final step is to perform an unbiased evaluation of our trained model on the held-out test set. We will visualize its predictions and calculate the Mean Absolute Error (MAE), comparing it to a simpler baseline model to prove the value of our complex architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/test_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_test = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m test_dataset = GranulationDataset(df_test, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n\u001b[32m      6\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m1\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Batch size 1 for individual plots\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/PharmaControl/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/test_data.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, 'test_data.csv'))\n",
    "test_dataset = GranulationDataset(df_test, CMA_COLS, CPP_COLS, LOOKBACK, HORIZON)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False) # Batch size 1 for individual plots\n",
    "\n",
    "# Load scalers for inverse transform\n",
    "scalers = joblib.load(os.path.join(DATA_DIR, 'scalers.joblib'))\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get one sample from the test set\n",
    "    past_cmas, past_cpps, future_cpps, future_cmas_target = next(iter(test_loader))\n",
    "    past_cmas, past_cpps, future_cpps = [b.to(DEVICE) for b in [past_cmas, past_cpps, future_cpps]]\n",
    "    \n",
    "    prediction_scaled = final_model(past_cmas, past_cpps, future_cpps).squeeze(0).cpu().numpy()\n",
    "    target_scaled = future_cmas_target.squeeze(0).cpu().numpy()\n",
    "\n",
    "# Inverse transform to original scale for plotting\n",
    "prediction_unscaled = np.zeros_like(prediction_scaled)\n",
    "target_unscaled = np.zeros_like(target_scaled)\n",
    "for i, col in enumerate(CMA_COLS):\n",
    "    prediction_unscaled[:, i] = scalers[col].inverse_transform(prediction_scaled[:, i].reshape(-1, 1)).flatten()\n",
    "    target_unscaled[:, i] = scalers[col].inverse_transform(target_scaled[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# --- Plotting --- \n",
    "fig, axes = plt.subplots(len(CMA_COLS), 1, figsize=(15, 8), sharex=True)\n",
    "fig.suptitle('Model Prediction vs. Ground Truth on Test Set', fontsize=16)\n",
    "for i, col in enumerate(CMA_COLS):\n",
    "    axes[i].plot(target_unscaled[:, i], label='Ground Truth', color='blue', linestyle='--')\n",
    "    axes[i].plot(prediction_unscaled[:, i], label='Prediction', color='red')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "axes[-1].set_xlabel('Time Steps into Horizon')\n",
    "plt.show()\n",
    "\n",
    "# TODO: Implement and train a baseline MLP model and compare its final test MAE here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharmacontrol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
