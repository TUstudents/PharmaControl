{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 Notebook 4: The Robust MPC Core: Integrating Intelligence\n",
    "\n",
    "**Project:** `RobustMPC-Pharma` (V2)\n",
    "**Goal:** To assemble our advanced components into the final `RobustMPCController`. This new controller core will be uncertainty-aware, adaptive to disturbances, and capable of sophisticated optimization. This is where all our hard work comes together.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Theory: The Pillars of a Robust Controller](#1.-Theory:-The-Pillars-of-a-Robust-Controller)\n",
    "2. [Implementing the `RobustMPCController` V2](#2.-Implementing-the-RobustMPCController-V2)\n",
    "3. [Standalone Test of the Integrated Controller](#3.-Standalone-Test-of-the-Integrated-Controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Theory: The Pillars of a Robust Controller\n",
    "\n",
    "Our V2 controller is built on three pillars that address the weaknesses of the V1 prototype:\n",
    "\n",
    "1.  **Stable State Perception (The Kalman Filter):** It will not react to raw sensor noise. Instead, it will act on a smooth, stable estimate of the true process state. This prevents control jitter and improves efficiency.\n",
    "\n",
    "2.  **Risk-Aware Decision Making (The Probabilistic Model):** The controller's cost function will not just evaluate the model's mean prediction. It will incorporate the model's uncertainty (standard deviation). By optimizing a **risk-adjusted** forecast (e.g., Upper Confidence Bound), the controller will act more cautiously when the model is uncertain, making it fundamentally safer.\n",
    "\n",
    "3.  **Adaptability to Disturbances (Integral Action):** Real-world processes suffer from un-modeled, persistent disturbances (e.g., gradual equipment fouling, changes in raw material). A standard controller will have a steady-state error in these cases. By implementing **Integral Action**, our controller will learn to recognize and automatically compensate for these disturbances, ensuring it always drives the process precisely to the target setpoint. This is known as **Offset-Free MPC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Implementing the `RobustMPCController` V2\n",
    "\n",
    "We will now create the final `RobustMPCController` class in `src/core.py`. This class will be a high-level orchestrator, managing the interactions between the state estimator, the predictive model, and the optimizer.\n",
    "\n",
    "The core logic will follow this sequence:\n",
    "1.  Receive a noisy measurement from the plant.\n",
    "2.  Use the `KalmanStateEstimator` to get a clean state estimate.\n",
    "3.  Update its internal `disturbance_estimate` using the error between the setpoint and the clean state (Integral Action).\n",
    "4.  Define a `fitness_function` for the optimizer. This function will:\n",
    "    a. Take a candidate control plan.\n",
    "    b. Get a probabilistic prediction from the `ProbabilisticTransformer`.\n",
    "    c. Add the `disturbance_estimate` to the mean prediction.\n",
    "    d. Calculate a risk-adjusted cost using the mean and standard deviation.\n",
    "5.  Pass this fitness function to the `GeneticOptimizer` to find the best control plan.\n",
    "6.  Return the first step of the winning plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../robust_mpc/core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../robust_mpc/core.py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class RobustMPCController:\n",
    "    \"\"\"\n",
    "    An advanced MPC controller that integrates a state estimator,\n",
    "    a probabilistic model, and a genetic algorithm optimizer for robust,\n",
    "    offset-free, and uncertainty-aware control.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, estimator, optimizer_class, config, scalers):\n",
    "        self.model = model\n",
    "        self.estimator = estimator\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.config = config\n",
    "        self.scalers = scalers\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Initialize the disturbance estimate for Integral Action\n",
    "        self.disturbance_estimate = np.zeros(len(config['cma_names']))\n",
    "\n",
    "    def _update_disturbance_estimate(self, smooth_state, setpoint):\n",
    "        \"\"\"Updates the integral error term for offset-free control.\"\"\"\n",
    "        error = setpoint - smooth_state\n",
    "        # The gain (alpha) determines how quickly the controller adapts to the disturbance\n",
    "        alpha = self.config.get('integral_gain', 0.1)\n",
    "        self.disturbance_estimate += alpha * error\n",
    "\n",
    "    def _get_fitness_function(self, past_cmas_scaled, past_cpps_scaled, target_cmas_unscaled):\n",
    "        \"\"\"\n",
    "        Creates and returns the fitness function to be used by the GA.\n",
    "        This function captures the current state and target.\n",
    "        \"\"\"\n",
    "        def fitness(control_plan_unscaled):\n",
    "            # --- 1. Prepare Inputs ---\n",
    "            # Scale the unscaled control plan generated by the GA\n",
    "            plan_scaled = self._scale_cpp_plan(control_plan_unscaled)\n",
    "            \n",
    "            # Convert all inputs to tensors\n",
    "            past_cmas_tensor = torch.tensor(past_cmas_scaled, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            past_cpps_tensor = torch.tensor(past_cpps_scaled, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            future_cpps_tensor = torch.tensor(plan_scaled, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "\n",
    "            # --- 2. Get Probabilistic Prediction ---\n",
    "            mean_pred_scaled, std_pred_scaled = self.model.predict_distribution(\n",
    "                past_cmas_tensor, past_cpps_tensor, future_cpps_tensor, \n",
    "                n_samples=self.config.get('mc_samples', 30)\n",
    "            )\n",
    "\n",
    "            # --- 3. Calculate Risk-Adjusted, Corrected Prediction ---\n",
    "            # Correct for disturbance (Integral Action)\n",
    "            disturbance_scaled = self._scale_cma_vector(self.disturbance_estimate)\n",
    "            corrected_mean_scaled = mean_pred_scaled + torch.tensor(disturbance_scaled, device=self.device)\n",
    "            \n",
    "            # Adjust for risk (Uncertainty-Awareness)\n",
    "            beta = self.config.get('risk_beta', 1.5) # Higher beta = more cautious\n",
    "            # For minimization, we penalize the upper bound of the error\n",
    "            risk_adjusted_pred_scaled = corrected_mean_scaled + beta * std_pred_scaled\n",
    "\n",
    "            # --- 4. Calculate Cost ---\n",
    "            target_scaled = self._scale_cma_plan(target_cmas_unscaled)\n",
    "            target_tensor = torch.tensor(target_scaled, dtype=torch.float32).to(self.device)\n",
    "            cost = torch.mean(torch.abs(risk_adjusted_pred_scaled - target_tensor))\n",
    "\n",
    "            return cost.item()\n",
    "        \n",
    "        return fitness\n",
    "        \n",
    "    def suggest_action(self, noisy_measurement, control_input, setpoint):\n",
    "        # 1. Get a clean state estimate\n",
    "        smooth_state = self.estimator.estimate(noisy_measurement, control_input)\n",
    "\n",
    "        # 2. Update the integral error term\n",
    "        self._update_disturbance_estimate(smooth_state, setpoint)\n",
    "\n",
    "        # 3. Create the fitness function for this specific time step\n",
    "        # This part requires getting the historical data, which we will simulate for the test.\n",
    "        # In a real app, this would come from a data buffer.\n",
    "        past_cmas_scaled, past_cpps_scaled = self._get_scaled_history(smooth_state)\n",
    "        \n",
    "        # The target is the setpoint repeated over the horizon\n",
    "        target_plan = np.tile(setpoint, (self.config['horizon'], 1))\n",
    "        fitness_func = self._get_fitness_function(past_cmas_scaled, past_cpps_scaled, target_plan)\n",
    "\n",
    "        # 4. Instantiate and run the optimizer\n",
    "        param_bounds = self._get_param_bounds()\n",
    "        optimizer = self.optimizer_class(fitness_func, param_bounds, self.config['ga_config'])\n",
    "        best_plan = optimizer.optimize()\n",
    "\n",
    "        # 5. Return the first step of the optimal plan\n",
    "        return best_plan[0]\n",
    "\n",
    "    # --- Helper methods for scaling and data management ---\n",
    "    def _get_scaled_history(self, current_smooth_state):\n",
    "        # In a real app, this would pull from a historical data buffer.\n",
    "        # For this test, we'll create dummy history.\n",
    "        L = self.config['lookback']\n",
    "        past_cmas_unscaled = np.tile(current_smooth_state, (L, 1))\n",
    "        past_cpps_unscaled = np.tile([120, 500, 30], (L, 1)) # Dummy CPPs\n",
    "        # Add soft sensors to CPPs\n",
    "        # ... (logic from notebook V1-2) ...\n",
    "        # Scale both\n",
    "        past_cmas_scaled = self._scale_cma_plan(past_cmas_unscaled)\n",
    "        past_cpps_scaled = self._scale_cpp_plan(past_cpps_unscaled, with_soft_sensors=True)\n",
    "        return past_cmas_scaled, past_cpps_scaled\n",
    "\n",
    "    def _scale_cpp_plan(self, plan_unscaled, with_soft_sensors=False):\n",
    "        # This needs to be implemented robustly, matching the training preprocessing\n",
    "        # For now, a placeholder\n",
    "        if with_soft_sensors: return np.zeros((plan_unscaled.shape[0], len(self.config['cpp_full_names'])))\n",
    "        return np.zeros_like(plan_unscaled)\n",
    "        \n",
    "    def _scale_cma_plan(self, plan_unscaled):\n",
    "        return np.zeros_like(plan_unscaled)\n",
    "\n",
    "    def _scale_cma_vector(self, vector_unscaled):\n",
    "        return np.zeros_like(vector_unscaled)\n",
    "        \n",
    "    def _get_param_bounds(self):\n",
    "        param_bounds = []\n",
    "        cpp_config = self.config['cpp_constraints']\n",
    "        for _ in range(self.config['horizon']):\n",
    "            for name in self.config['cpp_names']:\n",
    "                param_bounds.append((cpp_config[name]['min_val'], cpp_config[name]['max_val']))\n",
    "        return param_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Standalone Test of the Integrated Controller\n",
    "\n",
    "Before the final showdown in Notebook 5, let's do a quick standalone test of the new `RobustMPCController` class. This will ensure all the components are communicating correctly. We will mock the necessary inputs and call the main `.suggest_action()` method to see if it produces a sensible result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RobustMPCController initialized successfully!\n",
      "   - Model: ProbabilisticTransformer\n",
      "   - Estimator: str\n",
      "   - Optimizer: GeneticOptimizer\n",
      "   - Horizon: 10, Risk β: 1.5\n",
      "RobustMPCController class instantiated successfully!\n",
      "Note: The helper methods for scaling and history need to be fully implemented for the final test.\n"
     ]
    }
   ],
   "source": [
    "# This cell is for testing the class logic. A full implementation requires all components.\n",
    "# Due to the complexity of mocking all inputs (history, scalers, etc.), a full test is deferred to Notebook 5.\n",
    "# Here we will just instantiate the class to check for syntax errors.\n",
    "\n",
    "from V2.robust_mpc.core import RobustMPCController\n",
    "from V2.robust_mpc.estimators import KalmanStateEstimator\n",
    "from V2.robust_mpc.models import ProbabilisticTransformer\n",
    "from V2.robust_mpc.optimizers import GeneticOptimizer\n",
    "\n",
    "# --- Mock Components and Configs (for instantiation) ---\n",
    "mock_model = ProbabilisticTransformer(cma_features=2, cpp_features=5, d_model=32, nhead=2)\n",
    "mock_estimator = 'KalmanFilterPlaceholder'\n",
    "mock_optimizer_class = GeneticOptimizer\n",
    "mock_scalers = 'ScalersPlaceholder'\n",
    "\n",
    "MPC_CONFIG_V2 = {\n",
    "    'lookback': 36,\n",
    "    'horizon': 10, # Shorter for faster testing\n",
    "    'cma_names': ['d50', 'lod'],\n",
    "    'cpp_names': ['spray_rate', 'air_flow', 'carousel_speed'],\n",
    "    'cpp_full_names': ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy'],\n",
    "    'integral_gain': 0.1,\n",
    "    'risk_beta': 1.5,\n",
    "    'mc_samples': 10,\n",
    "    'cpp_constraints': {\n",
    "        'spray_rate': {'min_val': 80.0, 'max_val': 180.0},\n",
    "        'air_flow': {'min_val': 400.0, 'max_val': 700.0},\n",
    "        'carousel_speed': {'min_val': 20.0, 'max_val': 40.0}\n",
    "    },\n",
    "    'ga_config': {\n",
    "        'population_size': 40,\n",
    "        'num_generations': 15,\n",
    "        'crossover_prob': 0.7,\n",
    "        'mutation_prob': 0.2,\n",
    "        'horizon': 10, # Must match outer horizon\n",
    "        'num_cpps': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    controller = RobustMPCController(\n",
    "        model=mock_model,\n",
    "        estimator=mock_estimator,\n",
    "        optimizer_class=mock_optimizer_class,\n",
    "        config=MPC_CONFIG_V2,\n",
    "        scalers=mock_scalers\n",
    "    )\n",
    "    print(\"RobustMPCController class instantiated successfully!\")\n",
    "    print(\"Note: The helper methods for scaling and history need to be fully implemented for the final test.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during instantiation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Analysis and Next Steps\n",
    "\n",
    "We have successfully designed and implemented the architecture for our advanced `RobustMPCController`. This new core brings together all the state-of-the-art components we've developed in this V2 series. While we have only performed a basic instantiation test here, we have laid out the complete logic that will be put to the test in our final notebook.\n",
    "\n",
    "The key takeaways are:\n",
    "*   **Modular Design:** The controller is built to accept different estimators, models, and optimizers, making it highly flexible.\n",
    "*   **Integral Action:** The logic for `disturbance_estimate` is in place, ready to eliminate steady-state error.\n",
    "*   **Risk-Awareness:** The fitness function is designed to use the probabilistic output of our model, making the controller inherently safer.\n",
    "\n",
    "In the final notebook, we will implement the missing helper methods, connect this controller to our plant, and perform a head-to-head showdown against our V1 controller to definitively prove its superior performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharmacontrol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
