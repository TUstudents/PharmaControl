{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Phase 1 checkpoint decision\nprint(\"Phase 1 Checkpoint: Multi-Scenario Readiness Assessment\")\nprint(\"=\" * 54)\n\nif phase1_success:\n    print(f\"‚úÖ CHECKPOINT PASSED: Proceeding to Phase 2\")\n    print(f\"   Both controllers validated against V2-8/V2-9 baselines\")\n    print(f\"   Ready for multi-scenario performance comparison\")\n    print(f\"   Expected strategy differences confirmed\")\n    \n    proceed_to_phase2 = True\n    \n    # Save Phase 1 results\n    phase1_results = {\n        'timestamp': datetime.now().isoformat(),\n        'baseline_validation': baseline_results,\n        'controllers_ready': True,\n        'next_phase': 'Phase 2'\n    }\n    \nelse:\n    print(f\"‚ö†Ô∏è  CHECKPOINT CONCERNS: Controllers need attention\")\n    print(f\"   One or both controllers differ from expected baselines\")\n    print(f\"   Recommend investigation before proceeding\")\n    \n    proceed_to_phase2 = False\n    \n    # Save Phase 1 results with issues\n    phase1_results = {\n        'timestamp': datetime.now().isoformat(),\n        'baseline_validation': baseline_results,\n        'controllers_ready': False,\n        'issues': 'Baseline validation differs from expected',\n        'next_phase': 'Investigation needed'\n    }\n\n# Save results to file\nwith open(RESULTS_PATH / \"phase1_results.json\", 'w') as f:\n    json.dump(phase1_results, f, indent=2, default=str)\n\nprint(f\"\\nüìã Phase 1 results saved to: {RESULTS_PATH / 'phase1_results.json'}\")\nprint(f\"üöÄ Next action: {'Proceed to Phase 2' if proceed_to_phase2 else 'Investigate baseline differences'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Phase 1 Checkpoint: Ready for Multi-Scenario Comparison?\n\n**Decision Point**: Based on baseline validation results, determine if both controllers are ready for comprehensive comparison or if additional debugging is needed.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def validate_controller_baselines():\n    \"\"\"Validate both controllers produce expected actions from V2-8/V2-9.\n    \n    Expected Results:\n    - V1: [162.90, 556.22, 33.04] \n    - V2: [130.0, 550.0, 30.0]\n    \"\"\"\n    \n    print(\"Phase 1.4: Baseline Validation (V2-8/V2-9 Reproduction)\")\n    print(\"=\" * 56)\n    \n    # Test conditions IDENTICAL to V2-8/V2-9\n    test_setpoint = np.array([450.0, 1.4])  # d50=450Œºm, LOD=1.4%\n    \n    print(f\"Test Conditions (IDENTICAL to V2-8/V2-9):\")\n    print(f\"  Setpoint: d50={test_setpoint[0]:.0f}Œºm, LOD={test_setpoint[1]:.1f}%\")\n    print(f\"  Data: indices 2000-2036 (identical segment)\")\n    \n    results = {\n        'v1': {'expected': np.array([162.90, 556.22, 33.04]), 'actual': None, 'error': None},\n        'v2': {'expected': np.array([130.0, 550.0, 30.0]), 'actual': None, 'error': None}\n    }\n    \n    # Test V1 Controller\n    print(f\"\\nüîç Testing V1 Controller:\")\n    try:\n        # Create target for V1 (repeated for horizon)\n        horizon = v1_config['horizon']\n        target_cmas_v1 = np.tile(test_setpoint, (horizon, 1))\n        \n        start_time = time.time()\n        v1_action = v1_controller.suggest_action(\n            v1_cmas_df,\n            v1_cpps_df, \n            target_cmas_v1\n        )\n        v1_time = time.time() - start_time\n        \n        results['v1']['actual'] = v1_action\n        results['v1']['time'] = v1_time\n        \n        print(f\"   ‚úÖ V1 Action: {v1_action}\")\n        print(f\"   ‚úÖ Expected:  {results['v1']['expected']}\")\n        print(f\"   ‚úÖ Time: {v1_time:.3f}s\")\n        \n        # Check accuracy\n        v1_diff = np.abs(v1_action - results['v1']['expected'])\n        v1_max_diff = np.max(v1_diff)\n        \n        if v1_max_diff < 0.1:\n            print(f\"   üéâ V1 BASELINE PERFECT: Max diff {v1_max_diff:.6f}\")\n            results['v1']['status'] = 'perfect'\n        elif v1_max_diff < 1.0:\n            print(f\"   ‚úÖ V1 BASELINE GOOD: Max diff {v1_max_diff:.3f}\")\n            results['v1']['status'] = 'good'\n        else:\n            print(f\"   ‚ö†Ô∏è  V1 BASELINE DIFFERS: Max diff {v1_max_diff:.3f}\")\n            results['v1']['status'] = 'different'\n        \n    except Exception as e:\n        print(f\"   ‚ùå V1 Controller failed: {e}\")\n        results['v1']['error'] = str(e)\n        results['v1']['status'] = 'failed'\n    \n    # Test V2 Controller\n    print(f\"\\nüîç Testing V2 Controller:\")\n    try:\n        # Convert test state to arrays for V2\n        current_cmas_array = np.array([test_cmas['d50'], test_cmas['lod']])\n        current_cpps_array = np.array([test_cpps['spray_rate'], test_cpps['air_flow'], test_cpps['carousel_speed']])\n        \n        start_time = time.time()\n        v2_action = v2_controller.suggest_action(\n            noisy_measurement=current_cmas_array,\n            control_input=current_cpps_array,\n            setpoint=test_setpoint\n        )\n        v2_time = time.time() - start_time\n        \n        results['v2']['actual'] = v2_action\n        results['v2']['time'] = v2_time\n        \n        print(f\"   ‚úÖ V2 Action: {v2_action}\")\n        print(f\"   ‚úÖ Expected:  {results['v2']['expected']}\")\n        print(f\"   ‚úÖ Time: {v2_time:.3f}s\")\n        \n        # Check accuracy\n        v2_diff = np.abs(v2_action - results['v2']['expected'])\n        v2_max_diff = np.max(v2_diff)\n        \n        if v2_max_diff < 0.1:\n            print(f\"   üéâ V2 BASELINE PERFECT: Max diff {v2_max_diff:.6f}\")\n            results['v2']['status'] = 'perfect'\n        elif v2_max_diff < 1.0:\n            print(f\"   ‚úÖ V2 BASELINE GOOD: Max diff {v2_max_diff:.3f}\")\n            results['v2']['status'] = 'good'\n        else:\n            print(f\"   ‚ö†Ô∏è  V2 BASELINE DIFFERS: Max diff {v2_max_diff:.3f}\")\n            results['v2']['status'] = 'different'\n        \n    except Exception as e:\n        print(f\"   ‚ùå V2 Controller failed: {e}\")\n        results['v2']['error'] = str(e)\n        results['v2']['status'] = 'failed'\n        traceback.print_exc()\n    \n    # Overall validation assessment\n    print(f\"\\nüìä BASELINE VALIDATION SUMMARY:\")\n    print(f\"=\" * 35)\n    \n    v1_ok = results['v1']['status'] in ['perfect', 'good']\n    v2_ok = results['v2']['status'] in ['perfect', 'good']\n    \n    if v1_ok and v2_ok:\n        print(f\"üéâ PHASE 1 SUCCESS: Both controllers validated successfully\")\n        print(f\"   V1 Controller: {results['v1']['status'].upper()}\")\n        print(f\"   V2 Controller: {results['v2']['status'].upper()}\")\n        print(f\"   ‚úÖ Ready for Phase 2: Multi-scenario comparison\")\n        phase1_success = True\n    else:\n        print(f\"‚ö†Ô∏è  PHASE 1 ISSUES DETECTED:\")\n        if not v1_ok:\n            print(f\"   V1 Controller: {results['v1']['status'].upper()}\")\n        if not v2_ok:\n            print(f\"   V2 Controller: {results['v2']['status'].upper()}\")\n        print(f\"   üîÑ May need investigation before Phase 2\")\n        phase1_success = False\n    \n    # Performance comparison preview\n    if v1_ok and v2_ok:\n        print(f\"\\nüîç INITIAL PERFORMANCE PREVIEW:\")\n        v1_act = results['v1']['actual']\n        v2_act = results['v2']['actual']\n        \n        action_diff = np.abs(v1_act - v2_act)\n        max_diff = np.max(action_diff)\n        \n        print(f\"   Controller action difference: {max_diff:.3f}\")\n        print(f\"   V1 strategy: {v1_act}\")\n        print(f\"   V2 strategy: {v2_act}\")\n        print(f\"   Time ratio V2/V1: {results['v2']['time']/results['v1']['time']:.2f}x\")\n    \n    return results, phase1_success\n\n# Execute baseline validation\nbaseline_results, phase1_success = validate_controller_baselines()\n\nprint(f\"\\nüéØ Phase 1 Complete - Controllers {'validated' if phase1_success else 'need attention'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Phase 1.4: Baseline Validation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def create_v2_controller_validated():\n    \"\"\"Create V2 controller using exact patterns validated in V2-9.\n    \n    Expected result: action [130.0, 550.0, 30.0] with setpoint d50=450Œºm LOD=1.4%\n    \"\"\"\n    \n    print(\"Creating V2 Controller (Validated V2-9 Patterns)\")\n    print(\"=\" * 47)\n    \n    # Import V2 components exactly as in V2-9\n    from V2.robust_mpc.core import RobustMPCController\n    from V2.robust_mpc.estimators import KalmanStateEstimator\n    from V2.robust_mpc.optimizers import GeneticOptimizer\n    from V2.robust_mpc.data_buffer import DataBuffer\n    \n    # Create V2 DataBuffer with identical data from comparison_data\n    lookback = 36\n    buffer_size = 150\n    \n    v2_data_buffer = DataBuffer(\n        cma_features=2,  # d50, lod\n        cpp_features=3,  # spray_rate, air_flow, carousel_speed\n        buffer_size=buffer_size,\n        validate_sequence=True\n    )\n    \n    print(f\"‚úì V2 DataBuffer created with capacity: {buffer_size}\")\n    \n    # Populate buffer with identical data sequence using atomic operations\n    final_cmas = None\n    final_cpps = None\n    \n    for idx in range(len(comparison_data)):\n        row = comparison_data.iloc[idx]\n        \n        # Convert to numpy arrays for atomic add_sample operation\n        cma_array = np.array([row['d50'], row['lod']])\n        cpp_array = np.array([row['spray_rate'], row['air_flow'], row['carousel_speed']])\n        \n        # Use atomic operation\n        v2_data_buffer.add_sample(cma_array, cpp_array)\n        \n        # Store final state for testing\n        if idx == len(comparison_data) - 1:\n            final_cmas = {'d50': row['d50'], 'lod': row['lod']}\n            final_cpps = {\n                'spray_rate': row['spray_rate'],\n                'air_flow': row['air_flow'], \n                'carousel_speed': row['carousel_speed']\n            }\n    \n    current_size = len(v2_data_buffer)\n    print(f\"‚úì Buffer populated: {current_size}/{buffer_size} steps\")\n    print(f\"  Buffer ready for {lookback}-step lookback: {current_size >= lookback}\")\n    \n    # Load V2 configuration\n    with open(V2_CONFIG_PATH, 'r') as f:\n        v2_config_base = yaml.safe_load(f)\n    \n    # Create complete V2 configuration (using V2-9 patterns)\n    mpc_config = v2_config_base['mpc']\n    process_vars = v2_config_base['process_variables']\n    kalman_config = v2_config_base['kalman']\n    \n    # Build complete configuration\n    v2_config = {\n        # Root level keys (required by V2 controller)\n        'cma_names': process_vars['cma_names'],\n        'cpp_names': process_vars['cpp_names'],\n        'cpp_full_names': process_vars['cpp_full_names'],\n        'lookback': mpc_config['lookback'],\n        'horizon': mpc_config['horizon'],\n        'mc_samples': mpc_config['mc_samples'],\n        'cpp_constraints': process_vars['cpp_constraints'],\n        'scalers': comparison_scalers,\n        \n        # Genetic algorithm config (fixed key name from V2-9)\n        'ga_config': {\n            'population_size': mpc_config.get('population_size', 40),\n            'num_generations': mpc_config.get('generations', 15),  # num_generations not generations\n            'mutation_rate': mpc_config.get('mutation_rate', 0.1),\n            'crossover_rate': mpc_config.get('crossover_rate', 0.7)\n        },\n        \n        # Kalman parameters\n        'kalman': {\n            'process_noise': kalman_config.get('process_noise_std', 1.0),\n            'measurement_noise': kalman_config.get('measurement_noise_std', 15.0),\n            'initial_uncertainty': kalman_config.get('initial_covariance_scale', 1.0)\n        },\n        \n        # MPC parameters\n        'mpc': mpc_config,\n        'verbose': False  # Silent operation for comparison\n    }\n    \n    print(f\"‚úì V2 configuration created with all required keys\")\n    \n    # Create KalmanStateEstimator (using V2-9 patterns)\n    n_states = len(v2_config['cma_names'])  # 2\n    n_controls = len(v2_config['cpp_names'])  # 3\n    \n    transition_matrix = np.eye(n_states) * 0.95\n    control_matrix = np.ones((n_states, n_controls)) * 0.1\n    initial_state = np.array([final_cmas['d50'], final_cmas['lod']])\n    \n    estimator = KalmanStateEstimator(\n        transition_matrix=transition_matrix,\n        control_matrix=control_matrix,\n        initial_state_mean=initial_state,\n        process_noise_std=v2_config['kalman']['process_noise'],\n        measurement_noise_std=v2_config['kalman']['measurement_noise']\n    )\n    \n    print(f\"‚úì KalmanStateEstimator created\")\n    \n    # Create RobustMPCController\n    v2_controller = RobustMPCController(\n        model=comparison_model,\n        estimator=estimator,\n        optimizer_class=GeneticOptimizer,  # Pass class, not instance\n        config=v2_config,\n        scalers=v2_config['scalers'],\n        history_buffer=v2_data_buffer  # Pre-populated buffer\n    )\n    \n    print(f\"‚úì V2 RobustMPCController created successfully\")\n    print(f\"  Model device: {next(v2_controller.model.parameters()).device}\")\n    print(f\"  Estimator: {type(estimator).__name__}\")\n    print(f\"  Buffer ready: {len(v2_data_buffer) >= lookback}\")\n    \n    return v2_controller, v2_data_buffer, v2_config, final_cmas, final_cpps\n\n# Create V2 controller with validated patterns\nv2_controller, v2_data_buffer, v2_config, test_cmas, test_cpps = create_v2_controller_validated()\n\nprint(f\"\\nüéØ Phase 1.3 Complete - V2 controller ready for baseline testing\")\nprint(f\"   Final test state: d50={test_cmas['d50']:.1f}Œºm, LOD={test_cmas['lod']:.2f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Phase 1.3: V2 Controller Recreation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Phase 1.2: V1 Controller Recreation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def create_v1_controller_validated():\n    \"\"\"Create V1 controller using exact patterns validated in V2-8.\n    \n    Expected result: action [162.90, 556.22, 33.04] with setpoint d50=450Œºm LOD=1.4%\n    \"\"\"\n    \n    print(\"Creating V1 Controller (Validated V2-8 Patterns)\")\n    print(\"=\" * 47)\n    \n    # Import V1 components exactly as in V2-8\n    from V1.src.mpc_controller import MPCController as V1Controller\n    from V1.src.model_architecture import GranulationPredictor\n    \n    # Create perfect V1 DataFrames in unscaled engineering units\n    lookback = 36\n    \n    # CMAs: Critical Material Attributes (UNSCALED)\n    cma_columns = ['d50', 'lod']\n    v1_cmas_df = comparison_data[cma_columns].copy()\n    \n    # CPPs: Critical Process Parameters + Soft Sensors (UNSCALED)\n    cpp_columns = ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy']\n    v1_cpps_df = comparison_data[cpp_columns].copy()\n    \n    print(f\"‚úì V1 DataFrames created:\")\n    print(f\"  CMAs shape: {v1_cmas_df.shape}, columns: {list(v1_cmas_df.columns)}\")\n    print(f\"  CPPs shape: {v1_cpps_df.shape}, columns: {list(v1_cpps_df.columns)}\")\n    \n    # Validate data is in engineering units\n    d50_max = v1_cmas_df['d50'].max()\n    if d50_max > 100:\n        print(f\"  ‚úì Data in engineering units (d50 max: {d50_max:.1f} Œºm)\")\n    else:\n        print(f\"  ‚ùå WARNING: Data appears scaled (d50 max: {d50_max:.3f})\")\n    \n    # Create V1 configuration exactly as in V2-8\n    v1_config = {\n        # Core parameters\n        'lookback': lookback,\n        'horizon': 72,\n        \n        # Variable definitions\n        'cpp_names': ['spray_rate', 'air_flow', 'carousel_speed'],\n        'cma_names': ['d50', 'lod'],\n        'cpp_names_and_soft_sensors': ['spray_rate', 'air_flow', 'carousel_speed', 'specific_energy', 'froude_number_proxy'],\n        \n        # MPC parameters (optimized from V2-8 debugging)\n        'control_effort_lambda': 0.01,\n        'discretization_steps': 5,\n        \n        # Constraints\n        'cpp_constraints': {\n            'spray_rate': {'min_val': 80.0, 'max_val': 180.0, 'max_change_per_step': 15.0},\n            'air_flow': {'min_val': 400.0, 'max_val': 700.0, 'max_change_per_step': 30.0},\n            'carousel_speed': {'min_val': 20.0, 'max_val': 40.0, 'max_change_per_step': 3.0}\n        }\n    }\n    \n    # Create V1 controller\n    v1_controller = V1Controller(\n        model=comparison_model,\n        config=v1_config,\n        constraints=v1_config['cpp_constraints'],\n        scalers=comparison_scalers\n    )\n    \n    print(f\"‚úì V1 controller created successfully\")\n    print(f\"  Device: {v1_controller.device}\")\n    print(f\"  Model device: {next(v1_controller.model.parameters()).device}\")\n    \n    return v1_controller, v1_cmas_df, v1_cpps_df, v1_config\n\n# Create V1 controller with validated patterns\nv1_controller, v1_cmas_df, v1_cpps_df, v1_config = create_v1_controller_validated()\n\nprint(f\"\\nüéØ Phase 1.2 Complete - V1 controller ready for baseline testing\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2-10: Comprehensive V1 vs V2 Performance Comparison\n",
    "\n",
    "**Project:** RobustMPC-Pharma V2  \n",
    "**Version:** 2.10 - Comprehensive Controller Performance Analysis  \n",
    "**Date:** 2025-08-24  \n",
    "\n",
    "## Project Context\n",
    "\n",
    "Building on successful debugging in V2-8 (V1 controller) and V2-9 (V2 controller), this notebook performs systematic performance comparison between both controllers using the established 4-phase methodology.\n",
    "\n",
    "### Expected Baseline Results (from V2-8/V2-9)\n",
    "- **V1 Controller**: [162.90, 556.22, 33.04] (grid search optimization)\n",
    "- **V2 Controller**: [130.0, 550.0, 30.0] (genetic algorithm optimization)\n",
    "- **Test Conditions**: Data indices 2000-2036, setpoint d50=450Œºm LOD=1.4%\n",
    "\n",
    "## Strategic Objectives\n",
    "- **Direct Performance Comparison**: Test both controllers under identical conditions across multiple scenarios\n",
    "- **Statistical Analysis**: Compare optimization strategies, convergence behavior, and control effectiveness  \n",
    "- **Production Readiness Assessment**: Validate industrial deployment capabilities\n",
    "- **Decision Framework**: Provide data-driven controller selection criteria\n",
    "\n",
    "## 4-Phase Methodology\n",
    "**Phase 1:** Controller Setup & Validation (reproduce V2-8/V2-9 results)  \n",
    "**Phase 2:** Multi-Scenario Performance Testing (statistical comparison)  \n",
    "**Phase 3:** Advanced Feature Comparison (uncertainty, Kalman, optimization)  \n",
    "**Phase 4:** Analysis & Recommendations (deployment guidance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Controller Setup & Validation\n",
    "\n",
    "Ensure both controllers are properly configured with identical test data and reproduce expected results from V2-8/V2-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1.1: Environment & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced plotting setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"V2-10: Comprehensive V1 vs V2 Performance Comparison\")\n",
    "print(f\"=\" * 55)\n",
    "print(f\"Session Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Configuration\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "V1_DATA_PATH = Path(\"../../V1/data\")\n",
    "V2_CONFIG_PATH = Path(\"../../V2/config.yaml\")\n",
    "V2_MODEL_PATH = Path(\"../../V2/models\")\n",
    "RESULTS_PATH = Path(\"../../V2/comparison_results\")\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  V1 Data: {V1_DATA_PATH}\")\n",
    "print(f\"  V2 Config: {V2_CONFIG_PATH}\")\n",
    "print(f\"  Results: {RESULTS_PATH}\")\n",
    "print(f\"  Using IDENTICAL test conditions from V2-8/V2-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_identical_training_data():\n",
    "    \"\"\"Load identical training data used in V2-8 and V2-9.\n",
    "    \n",
    "    CRITICAL: Must produce IDENTICAL data to V2-8/V2-9 for baseline validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading Identical Training Data (V2-8/V2-9 Reproduction)\")\n",
    "    print(\"=\" * 57)\n",
    "    \n",
    "    # Load exact same data as V2-8/V2-9\n",
    "    try:\n",
    "        raw_data = pd.read_csv(V1_DATA_PATH / \"train_data_raw.csv\")\n",
    "        print(f\"‚úì Raw training data loaded: {len(raw_data):,} samples\")\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            raw_data = pd.read_csv(V1_DATA_PATH / \"granulation_data_raw.csv\")\n",
    "            print(f\"‚úì Raw granulation data loaded: {len(raw_data):,} samples\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Raw data not found, generating from scaled data...\")\n",
    "            scaled_data = pd.read_csv(V1_DATA_PATH / \"train_data.csv\")\n",
    "            scalers = joblib.load(V1_DATA_PATH / \"scalers.joblib\")\n",
    "            \n",
    "            raw_data = scaled_data.copy()\n",
    "            for col in scaled_data.columns:\n",
    "                if col in scalers:\n",
    "                    scaler = scalers[col]\n",
    "                    raw_data[col] = scaler.inverse_transform(scaled_data[[col]]).flatten()\n",
    "            \n",
    "            print(f\"‚úì Generated unscaled data from scaled data: {len(raw_data):,} samples\")\n",
    "    \n",
    "    # Load V1 scalers and model\n",
    "    scalers = joblib.load(V1_DATA_PATH / \"scalers.joblib\")\n",
    "    print(f\"‚úì V1 scalers loaded: {list(scalers.keys())}\")\n",
    "    \n",
    "    # Load model for testing (try V2 model first, fallback to V1)\n",
    "    from V2.robust_mpc.models import load_trained_model\n",
    "    \n",
    "    v2_model_path = V2_MODEL_PATH / \"best_model.pth\"\n",
    "    v1_model_path = V1_DATA_PATH / \"best_predictor_model.pth\"\n",
    "    \n",
    "    if v2_model_path.exists():\n",
    "        model = load_trained_model(v2_model_path, device=DEVICE, validate=True)\n",
    "        model_source = \"V2\"\n",
    "        print(f\"‚úì V2 model loaded: {v2_model_path}\")\n",
    "    else:\n",
    "        model = load_trained_model(v1_model_path, device=DEVICE, validate=True)\n",
    "        model_source = \"V1\"\n",
    "        print(f\"‚úì V1 model loaded as fallback: {v1_model_path}\")\n",
    "    \n",
    "    # CRITICAL: Use IDENTICAL data segment as V2-8/V2-9 (indices 2000-2036)\n",
    "    start_idx = 2000\n",
    "    lookback = 36\n",
    "    end_idx = start_idx + lookback  # 2036\n",
    "    \n",
    "    if len(raw_data) < end_idx:\n",
    "        start_idx = len(raw_data) - lookback - 100\n",
    "        end_idx = start_idx + lookback\n",
    "    \n",
    "    data_segment = raw_data.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    print(f\"\\n‚úì Extracted IDENTICAL data segment: indices {start_idx}-{end_idx}\")\n",
    "    print(f\"  Shape: {data_segment.shape}\")\n",
    "    print(f\"  Columns: {list(data_segment.columns)}\")\n",
    "    \n",
    "    # Validate data ranges (should match V2-8/V2-9)\n",
    "    print(f\"\\nData ranges (should match V2-8/V2-9 exactly):\")\n",
    "    for col in ['d50', 'lod', 'spray_rate', 'air_flow', 'carousel_speed']:\n",
    "        if col in data_segment.columns:\n",
    "            print(f\"  {col}: [{data_segment[col].min():.1f}, {data_segment[col].max():.1f}]\")\n",
    "    \n",
    "    return data_segment, scalers, model, model_source\n",
    "\n",
    "# Load identical components for both V1 and V2 testing\n",
    "comparison_data, comparison_scalers, comparison_model, model_source = load_identical_training_data()\n",
    "\n",
    "print(f\"\\nüéØ Phase 1.1 Complete - Identical data loaded successfully\")\n",
    "print(f\"   Model source: {model_source}\")\n",
    "print(f\"   Data segment ready for controller comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}